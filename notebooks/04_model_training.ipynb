{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Model Training\n",
    "\n",
    "This notebook builds the hybrid DistilBERT + meta-features model and trains it on the preprocessed data.\n",
    "\n",
    "## Model Architecture:\n",
    "- **Base Model**: DistilBERT for sequence classification\n",
    "- **Meta Features**: 10 normalized engineered features\n",
    "- **Hybrid Approach**: Concatenate BERT embeddings with meta-features\n",
    "- **Classification**: Binary classification (disaster vs non-disaster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Load Preprocessed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load cleaned datasets\n",
    "df_train = pd.read_csv('../Data/train_cleaned.csv')\n",
    "df_test = pd.read_csv('../Data/test_cleaned.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare training data\n",
    "X_text = df_train['text_clean'].values\n",
    "y = df_train['target'].values\n",
    "X_meta = df_train[meta_cols].values\n",
    "\n",
    "print(f\"Text data shape: {X_text.shape}\")\n",
    "print(f\"Meta features shape: {X_meta.shape}\")\n",
    "print(f\"Target shape: {y.shape}\")\n",
    "\n",
    "# Split into train and validation sets\n",
    "X_text_train, X_text_val, X_meta_train, X_meta_val, y_train, y_val = train_test_split(\n",
    "    X_text, X_meta, y,\n",
    "    test_size=config['training_config']['val_split'],\n",
    "    random_state=config['training_config']['random_seed'],\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "print(f\"\\nTraining set size: {len(X_text_train)}\")\n",
    "print(f\"Validation set size: {len(X_text_val)}\")\n",
    "print(f\"Training class distribution: {np.bincount(y_train)}\")\n",
    "print(f\"Validation class distribution: {np.bincount(y_val)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Tokenization Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize tokenizer\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained(config['model_config']['model_name'])\n",
    "\n",
    "# Tokenization function\n",
    "def tokenize_function(texts, max_length=None):\n",
    "    if max_length is None:\n",
    "        max_length = config['model_config']['max_length']\n",
    "    \n",
    "    return tokenizer(\n",
    "        texts.tolist() if isinstance(texts, np.ndarray) else texts,\n",
    "        truncation=True,\n",
    "        padding='max_length',\n",
    "        max_length=max_length,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "\n",
    "# Tokenize training and validation data\n",
    "print(\"Tokenizing training data...\")\n",
    "train_encodings = tokenize_function(X_text_train)\n",
    "\n",
    "print(\"Tokenizing validation data...\")\n",
    "val_encodings = tokenize_function(X_text_val)\n",
    "\n",
    "print(\"Tokenizing test data...\")\n",
    "test_texts = df_test['text_clean'].values\n",
    "test_meta = df_test[meta_cols].values\n",
    "test_encodings = tokenize_function(test_texts)\n",
    "\n",
    "print(f\"\\nTokenization completed!\")\n",
    "print(f\"Training encodings shape: {train_encodings['input_ids'].shape}\")\n",
    "print(f\"Validation encodings shape: {val_encodings['input_ids'].shape}\")\n",
    "print(f\"Test encodings shape: {test_encodings['input_ids'].shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4 Custom Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DisasterTweetDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Custom dataset class for combining BERT tokens with meta-features.\n",
    "    \"\"\"\n",
    "    def __init__(self, encodings, meta_features, labels=None):\n",
    "        self.encodings = encodings\n",
    "        self.meta_features = torch.FloatTensor(meta_features)\n",
    "        self.labels = torch.LongTensor(labels) if labels is not None else None\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.meta_features)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        item = {\n",
    "            'input_ids': self.encodings['input_ids'][idx],\n",
    "            'attention_mask': self.encodings['attention_mask'][idx],\n",
    "            'meta_features': self.meta_features[idx]\n",
    "        }\n",
    "        \n",
    "        if self.labels is not None:\n",
    "            item['labels'] = self.labels[idx]\n",
    "        \n",
    "        return item\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = DisasterTweetDataset(train_encodings, X_meta_train, y_train)\n",
    "val_dataset = DisasterTweetDataset(val_encodings, X_meta_val, y_val)\n",
    "test_dataset = DisasterTweetDataset(test_encodings, test_meta)\n",
    "\n",
    "print(f\"Training dataset size: {len(train_dataset)}\")\n",
    "print(f\"Validation dataset size: {len(val_dataset)}\")\n",
    "print(f\"Test dataset size: {len(test_dataset)}\")\n",
    "\n",
    "# Sample from dataset\n",
    "sample = train_dataset[0]\n",
    "print(f\"\\nSample data keys: {list(sample.keys())}\")\n",
    "print(f\"Input IDs shape: {sample['input_ids'].shape}\")\n",
    "print(f\"Meta features shape: {sample['meta_features'].shape}\")\n",
    "print(f\"Label: {sample['labels']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.5 Hybrid Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HybridDistilBERTClassifier(nn.Module):\n",
    "    \"\"\"\n",
    "    Hybrid model combining DistilBERT with meta-features.\n",
    "    \"\"\"\n",
    "    def __init__(self, bert_model_name, num_meta_features, num_labels=2, dropout=0.2):\n",
    "        super().__init__()\n",
    "        \n",
    "        # DistilBERT model\n",
    "        self.bert = DistilBertModel.from_pretrained(bert_model_name)\n",
    "        self.bert_dim = self.bert.config.hidden_size\n",
    "        \n",
    "        # Meta-feature processing\n",
    "        self.meta_bn = nn.BatchNorm1d(num_meta_features)\n",
    "        self.meta_fc = nn.Linear(num_meta_features, 32)\n",
    "        self.meta_activation = nn.ReLU()\n",
    "        self.meta_dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        # Combined features\n",
    "        combined_dim = self.bert_dim + 32\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(combined_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(64, num_labels)\n",
    "        )\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask, meta_features):\n",
    "        # BERT encoding\n",
    "        bert_outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        bert_pooled = bert_outputs.last_hidden_state[:, 0, :]  # CLS token\n",
    "        \n",
    "        # Meta-feature processing\n",
    "        meta_processed = self.meta_bn(meta_features)\n",
    "        meta_processed = self.meta_fc(meta_processed)\n",
    "        meta_processed = self.meta_activation(meta_processed)\n",
    "        meta_processed = self.meta_dropout(meta_processed)\n",
    "        \n",
    "        # Combine features\n",
    "        combined = torch.cat([bert_pooled, meta_processed], dim=1)\n",
    "        \n",
    "        # Classification\n",
    "        logits = self.classifier(combined)\n",
    "        \n",
    "        return logits\n",
    "\n",
    "# Initialize model\n",
    "model = HybridDistilBERTClassifier(\n",
    "    bert_model_name=config['model_config']['model_name'],\n",
    "    num_meta_features=len(meta_cols),\n",
    "    num_labels=config['model_config']['num_labels'],\n",
    "    dropout=config['model_config']['dropout']\n",
    ")\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "print(f\"Model created successfully!\")\n",
    "print(f\"Total parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "print(f\"Trainable parameters: {sum(p.numel() for p in model.parameters() if p.requires_grad):,}\")\n",
    "\n",
    "# Model architecture summary\n",
    "print(\"\\nModel Architecture:\")\n",
    "print(f\"- BERT model: {config['model_config']['model_name']}\")\n",
    "print(f\"- BERT dimension: {model.bert_dim}\")\n",
    "print(f\"- Meta features: {len(meta_cols)}\")\n",
    "print(f\"- Meta processed dimension: 32\")\n",
    "print(f\"- Combined dimension: {model.bert_dim + 32}\")\n",
    "print(f\"- Output classes: {config['model_config']['num_labels']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.6 Training Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data loaders\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=config['model_config']['batch_size'],\n",
    "    shuffle=True,\n",
    "    num_workers=2\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=config['model_config']['batch_size'],\n",
    "    shuffle=False,\n",
    "    num_workers=2\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=config['model_config']['batch_size'],\n",
    "    shuffle=False,\n",
    "    num_workers=2\n",
    ")\n",
    "\n",
    "print(f\"Data loaders created:\")\n",
    "print(f\"Train batches: {len(train_loader)}\")\n",
    "print(f\"Validation batches: {len(val_loader)}\")\n",
    "print(f\"Test batches: {len(test_loader)}\")\n",
    "\n",
    "# Setup optimizer and scheduler\n",
    "optimizer = AdamW(\n",
    "    model.parameters(),\n",
    "    lr=config['model_config']['learning_rate'],\n",
    "    weight_decay=0.01\n",
    ")\n",
    "\n",
    "num_training_steps = len(train_loader) * config['model_config']['num_epochs']\n",
    "lr_scheduler = get_scheduler(\n",
    "    name=\"linear\",\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=config['training_config']['warmup_steps'],\n",
    "    num_training_steps=num_training_steps\n",
    ")\n",
    "\n",
    "# Loss function\n",
    "criterion = nn.CrossEntropyLoss().to(device)  # Move criterion to device\n",
    "\n",
    "print(f\"\\nTraining setup completed:\")\n",
    "print(f\"Optimizer: AdamW with lr={config['model_config']['learning_rate']}\")\n",
    "print(f\"Scheduler: Linear decay over {num_training_steps} steps\")\n",
    "print(f\"Loss function: CrossEntropyLoss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.7 Training Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train_epoch(model, dataloader, optimizer, scheduler, criterion, device):\n",
    "    \"\"\"\n",
    "    Train model for one epoch.\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "    \n",
    "    progress_bar = tqdm(dataloader, desc=\"Training\")\n",
    "    \n",
    "    for batch in progress_bar:\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Move inputs to device\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        meta_features = batch['meta_features'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(input_ids, attention_mask, meta_features)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), config['training_config']['gradient_clipping'])\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        # Statistics\n",
    "        total_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct_predictions += (predicted == labels).sum().item()\n",
    "        total_predictions += labels.size(0)\n",
    "        \n",
    "        # Update progress bar\n",
    "        current_loss = total_loss / len(dataloader)\n",
    "        current_acc = correct_predictions / total_predictions\n",
    "        progress_bar.set_postfix({\n",
    "            'loss': f'{current_loss:.4f}',\n",
    "            'acc': f'{current_acc:.4f}'\n",
    "        })\n",
    "    \n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    accuracy = correct_predictions / total_predictions\n",
    "    \n",
    "    return avg_loss, accuracy\n",
    "\n",
    "def evaluate_epoch(model, dataloader, criterion, device):\n",
    "    \"\"\"\n",
    "    Evaluate model on validation set.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, desc=\"Evaluating\"):\n",
    "            # Move inputs to device\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            meta_features = batch['meta_features'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(input_ids, attention_mask, meta_features)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # Statistics\n",
    "            total_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct_predictions += (predicted == labels).sum().item()\n",
    "            total_predictions += labels.size(0)\n",
    "            \n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    accuracy = correct_predictions / total_predictions\n",
    "    f1 = f1_score(all_labels, all_predictions, average='weighted')\n",
    "    \n",
    "    return avg_loss, accuracy, f1, all_predictions, all_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.8 Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "      print(f\"New best model saved! (F1: {val_f1:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.9 Training Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training history saved to results/metrics/training_history.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.10 Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Confusion matrix saved to results/visualizations/confusion_matrix.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.11 Save Model Artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Model artifacts saved:\")\n",
    "print(\"- models/best_model.pth (best checkpoint)\")\n",
    "print(\"- models/final_model.pth (final model)\")\n",
    "print(\"- models/model_info.json (model metadata)\")\n",
    "print(\"- results/metrics/training_history.json\")\n",
    "print(\"- results/visualizations/confusion_matrix.png\")\n",
    "\n",
    "print(\"\")\n",
    "print(\"=\"*60)\n",
    "print(\"Model training completed successfully!\")\n",
    "print(f\"Best validation F1 score: {best_val_f1:.4f}\")\n",
    "print(f\"Model saved for next notebook: 05_evaluation_prediction.ipynb\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (nlp-env)",
   "language": "python",
   "name": "nlp-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
